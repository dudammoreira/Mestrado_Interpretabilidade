# -*- coding: utf-8 -*-
"""Cópia de Mestrado_CarregamentoImagens.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VuGnFKR5Znan4DU8W7sE-WuoeU_SpOCK

### 0. Importando Bibliotecas
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import cv2
from numpy import asarray
import matplotlib.pyplot as plt
from matplotlib import image
# %matplotlib inline
import os
import tensorflow as tf
import tensorflow_hub as hub
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
import sklearn
import seaborn
import PIL
from PIL import Image

"""### 0.1 Conectando com o Drive"""

from google.colab import drive
drive.mount('/content/drive')

os.chdir('/content/drive/MyDrive/Mestrado/imagens_cafeferrugem/')

"""### 1.Manipulando a Imagem

"""

#Leitura da imagem caixa
image = Image.open("/content/drive/MyDrive/Mestrado/imagens_cafeferrugem/DSC_0307.JPG")
image

#Formato da imagem pura
print(image.format)
print(image.mode)
print(image.size)

#Leitura da imagem caixa com ajuste de tamanho
image = Image.open("/content/drive/MyDrive/Mestrado/imagens_cafeferrugem/DSC_0307.JPG")
image.thumbnail((224,224))
image

print(image.size)

image_resize = image.resize((120,120))
image_resize

#Tratando a imagem
image = Image.open("/content/drive/MyDrive/Mestrado/imagens_cafeferrugem/DSC_0307.JPG")
pixels = asarray(image)
print("Data Type: %s"% pixels.dtype)
print("Min: %.3f, Max: %.3f"% (pixels.min(),pixels.max()))

#Normalização da imagem
pixels = pixels.astype('float32')
pixels /= pixels.max()
print("Data Type: %s"% pixels.dtype)
print("Min: %.3f, Max: %.3f"% (pixels.min(),pixels.max()))

"""### 2. Criando o DataSet

####2.1 Caixa_Ferrugem
"""

#Leitura das imagens da caixa
import cv2

data_caixa = []
imagePaths = ("DSC_0307.JPG","DSC_0308.JPG","DSC_0309.JPG","DSC_0310.JPG","DSC_0311.JPG","DSC_0312.JPG",
              "DSC_0313.JPG","DSC_0314.JPG","DSC_0368.JPG","DSC_0369.JPG","DSC_0370.JPG","DSC_0371.JPG",
              "DSC_0372.JPG")
drivePath = "/content/drive/MyDrive/Mestrado/imagens_cafeferrugem/"

##Loop no input das imagens
for imagePath in imagePaths:
    ###Carregar as imagens e guardar em uma lista
    image = cv2.imread(drivePath+imagePath)
    data_caixa.append(image)

"""####2.2 Crop Ferrugem"""

#Leitura das imagens recorte ferrugem
##Construção dos caminhos de busca
imagePath = ()

string_i = "ferr00"
string_f = ".jpg"
for i in range(1,10):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "ferr0"
for i in range(10,100):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "ferr"
for i in range(100,384):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

#Elaboração dataset recortes ferrugem
data_ferrugem = []
drivePath = "/content/drive/MyDrive/Mestrado/imagens_ferrugem/"
##Loop no input das imagens
for imagePath in imagePath:
    ###Carregar as imagens e guardar em uma lista
    image = cv2.imread(drivePath+imagePath)
    data_ferrugem.append(image)

"""####2.3 Crop Phoma"""

#Leitura das imagens recorte phoma
##Construção dos caminhos de busca
imagePath = ()

string_i = "phom00"
string_f = ".jpg"
for i in range(1,10):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "phom0"
for i in range(10,53):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

#Elaboração dataset recortes phoma
data_phoma = []
drivePath = "/content/drive/MyDrive/Mestrado/imagens_phoma/"
##Loop no input das imagens
for imagePath in imagePath:
    ###Carregar as imagens e guardar em uma lista
    image = cv2.imread(drivePath+imagePath)
    data_phoma.append(image)

"""####2.4 Crop Manteigosa"""

#Leitura das imagens recorte mantegosa
##Construção dos caminhos de busca
imagePath = ()

string_i = "mman00"
string_f = ".jpg"
for i in range(1,10):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "mman0"
for i in range(10,100):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "mman"
for i in range(100,176):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

#Elaboração dataset recortes manteigosa
data_mantegosa = []
drivePath = "/content/drive/MyDrive/Mestrado/imagens_mantegosa/"
##Loop no input das imagens
for imagePath in imagePath:
    ###Carregar as imagens e guardar em uma lista
    image = cv2.imread(drivePath+imagePath)
    data_mantegosa.append(image)

"""####2.5 Crop Cercosporiose"""

#Leitura das imagens recorte cercosporiose
##Construção dos caminhos de busca
imagePath = ()

string_i = "cerc00"
string_f = ".jpg"
for i in range(1,10):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

string_i = "cerc0"
for i in range(10,89):
  path = string_i+str(i)+string_f
  imagePath = imagePath + (path,)

#Elaboração dataset recortes cercosporiose
data_cercospirose = []
drivePath = "/content/drive/MyDrive/Mestrado/imagens_cercospirose/"
##Loop no input das imagens
for imagePath in imagePath:
    ###Carregar as imagens e guardar em uma lista
    image = cv2.imread(drivePath+imagePath)
    data_cercospirose.append(image)

"""####2.6 Classes"""

#Criando dicionário de doenças
coffee_leaves_images_dict = {
    'ferrugem': list(data_ferrugem),
    'cercosporiose': list(data_cercospirose),
    'phoma': list(data_phoma),
    'manteigosa': list(data_mantegosa)
}

#Criando dicionário de labels
coffee_leaves_labels_dict = {
    'ferrugem': 0,
    'cercosporiose': 1,
    'phoma': 2,
    'manteigosa' : 3
}

"""####2.7 Tratamento Base"""

IMAGE_SHAPE = (224, 224)

#Ajuste no shape/size do banco de dados
X, y = [], []

for doenca, imagePath in coffee_leaves_images_dict.items():
    for imagePath in imagePath:
        ##Ajustando o tamanho das imagens
        resized_img = cv2.resize(imagePath,IMAGE_SHAPE)
        X.append(resized_img)
        y.append(coffee_leaves_labels_dict[doenca])

#Normalizando as imagens
X = np.array(X)
y = np.array(y)

#Train Test Split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.75, random_state=0, stratify=y)

y_train

#from sklearn.model_selection import StratifiedKFold, KFold
#skf = StratifiedKFold(n_splits=5)
#for train, test in skf.split(X, y):
#  print('train -  {}   |   test -  {}'.format(
#        np.bincount(y[train]), np.bincount(y[test])))

"""#3 Iniciar teste modelo Mobile Net (Google

##https://www.youtube.com/watch?v=LsdxvjLWkIY
"""

#Importando modelo para TL
##Testar MOBILE NET V2 (Google)
IMAGE_SHAPE = (224, 224)

classifier = tf.keras.Sequential([
    hub.KerasLayer("https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4", input_shape=IMAGE_SHAPE+(3,))
])

#Testando a classificação com uma imagem comum de goldfish
##Essa é uma das classes contidas na mobile net V2
gold_fish = Image.open("/content/drive/MyDrive/Mestrado/imagens_testes/goldfish.png").resize(IMAGE_SHAPE)
gold_fish

#Como a escala de cor é de 0 a 255, normalizamos
##Dividir por 255 para ficar com números de 0 a 1
gold_fish = np.array(gold_fish)/255.0
gold_fish.shape

#Adicionar mais uma dimensão
##Para predição não é possível ter só uma diemnsão
gold_fish[np.newaxis, ...]

#Predizer a probabilidade da imagem em umas das muitas classes da rede
##Imprime a probabilidade de ser daquela classe para cada uma delas
result = classifier.predict(gold_fish[np.newaxis, ...])
result.shape

#Busca a maior pontuação para identificar a classe que a imagem se identifica
##Imprime a label predita
predicted_label_index = np.argmax(result)
predicted_label_index

#Baixar as informações de classe txt no endereço :
##tf.keras.utils.get_file('ImageNetLabels.txt','https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt')
image_labels = []
with open("/content/drive/MyDrive/Mestrado/ImageNetLabels.txt", "r") as f:
    image_labels = f.read().splitlines()
image_labels[:5]

#Imprime classe classificada para a imagem
image_labels[predicted_label_index]

"""## 3.1 Utilizando o banco de dados do café no MobileNet V2"""

#Predizer usando um modelo pré-treinado em um novo data set
plt.axis('off')
plt.imshow(X[1])

x0_resized = cv2.resize(X[0], IMAGE_SHAPE)
x1_resized = cv2.resize(X[1], IMAGE_SHAPE)
x2_resized = cv2.resize(X[2], IMAGE_SHAPE)

predicted = classifier.predict(np.array([x0_resized, x1_resized, x2_resized]))
predicted = np.argmax(predicted, axis=1)
predicted

image_labels[905]

"""## 3.2 Retreinando o modelo"""

#https://www.tensorflow.org/tutorials/images/transfer_learning?hl=pt-br
feature_extractor_model = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"
pretrained_model_without_top_layer = hub.KerasLayer(
    feature_extractor_model, input_shape=(224, 224, 3), trainable=False)

#Definir número de classes
num_doenca = 4

model_netv2 = tf.keras.Sequential([
  #Utiliza o modelo anterior para treino
  pretrained_model_without_top_layer,
  #Somente a última camada é nova no retreino (nossos dados)
  tf.keras.layers.Dense(num_doenca,activation='softmax')
])

model_netv2.summary()

#Processando o tamanho das imagens
X_train_scaled = X_train / 255
X_test_scaled = X_test / 255

#para definir parâmetros: https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile
##adam optmizer: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam
model_netv2.compile(
  optimizer="adam",
  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
  metrics= ['accuracy', 'mse']
  #weighted_metrics=['accuracy', ['accuracy', 'mse']]
  )

# Testar com 5 epochs
model_netv2_fit = model_netv2.fit(X_train_scaled, y_train, epochs=5)

#Avaliando a performance do modelo
model_netv2.evaluate(X_test_scaled,y_test)

y_pred = []
for x in X_test_scaled:
  pred = model_netv2.predict(np.array([x]))
  pred = np.argmax(pred)
  y_pred.append(pred)

#y_test = y_test.tolist()
y_true = y_test
y_pred = y_pred

from sklearn.metrics import f1_score
f1 = f1_score(y_true,y_pred,average='weighted')
print(f1)

Categories = ['ferrugem','cercosporiose','phoma','manteigosa']
from sklearn.metrics import confusion_matrix
import seaborn as sns
mat = confusion_matrix(y_test, y_pred)
sns.heatmap(mat.T, square=True, annot=True, fmt='d',
            cbar=False, cmap='Blues',
            xticklabels=Categories,
            yticklabels=Categories)
plt.xlabel('true label')
plt.ylabel('predicted label');

Categories = ['ferrugem','cercosporiose','phoma','manteigosa']

fig, ax = plt.subplots(4, 6)
for i, axi in enumerate(ax.flat):
    axi.imshow(X_test_scaled[i].reshape(224,224,3), cmap='bone')
    axi.set(xticks=[], yticks=[])
    axi.set_ylabel(Categories[y_pred[i]].split()[-1],
                   color='black' if y_pred[i] == y_test[i] else 'red')
fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);

"""Exemplo de uma predição única"""

#Testando os resultados do modelo
x540 = cv2.resize(X[38], IMAGE_SHAPE)
predicted = model_netv2.predict(np.array([x540]))
predicted = np.argmax(predicted)
predicted

#Predizendo e plotando a imagem com as informações da categoria
x38 = cv2.resize(X[38], IMAGE_SHAPE)

plt.imshow(x38)
predicted = model_netv2.predict(np.array([x38]))
for x in np.argmax(predicted,axis=1):
    print(x)

"""# 4 Interpretando os resultados

## 4.1 LIME

###https://www.youtube.com/watch?v=Op2M5CpJehM&t=1039s
"""

import keras
from keras.applications import inception_v3 as inc_net
from keras.preprocessing import image
from tensorflow.keras.utils import load_img
from keras.applications.imagenet_utils import decode_predictions
from skimage.io import imread
print('Notebook run using keras:',keras.__version__)

inet_model = inc_net.InceptionV3()

#Função para carregar e transformar a imagem
def transform_img_fn(path_list):
    out = []
    for img_path in path_list:
        img = load_img(img_path, target_size=(299, 299))
        x = tf.keras.utils.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = inc_net.preprocess_input(x)
        out.append(x)
    return np.vstack(out)

#Predizendo e plotando a imagem com as informações da categoria
#O modelo previu 82% de chance de ser uma elefante africano
images = transform_img_fn([os.path.join('/content/drive/MyDrive/Mestrado/imagens_testes/elephant.jpeg')])
# Dividindo por 2 e adicionando 0.5 por caussa de como essa Inception representa as imagens
plt.imshow(images[0] / 2 + 0.5)
preds = inet_model.predict(images)
for x in decode_predictions(preds)[0]:
    print(x)

!pip install lime

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2
import os,sys
try:
    import lime
except:
    sys.path.append(os.path.join('..', '..')) # add the current directory
    import lime
from lime import lime_image

explainer = lime_image.LimeImageExplainer()

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels
# explanation = explainer.explain_instance(images[0].astype('double'), inet_model.predict, top_labels=5, hide_color=0, num_samples=1000)
#

explanation

from skimage.segmentation import mark_boundaries

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
##pros in green
##cons in red
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#pros and cons
##With weight at least 0.1
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=1000, hide_rest=False, min_weight=0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Explaination Heatmap plot with weights
##Colorbar shows the values of the weights
#Select the same class explained on the figures above.
ind =  explanation.top_labels[0]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

#Second Prediction in the list
##Superpixel for the second most Prediction
temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=True, num_features=5, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

temp, mask = explanation.get_image_and_mask(explanation.top_labels[1], positive_only=False, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Select the same class explained on the figures above.
ind =  explanation.top_labels[1]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

"""### 4.1.1 Testando o Lime no modelo Mobile Net para a Café - Ferrugem"""

#Predizendo e plotando a imagem com as informações da categoria
x38 = cv2.resize(X[38], IMAGE_SHAPE)
x38 = x38/255

y[38]

plt.imshow(x38)
predicted = model_netv2.predict(np.array([x38]))
for x in np.argmax(predicted,axis=1):
    print(x)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels
# explanation = explainer.explain_instance(x38, model_netv2.predict, top_labels=5, hide_color=0, num_samples=1000)
# explanation

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
##pros in green
##cons in red
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Explaination Heatmap plot with weights
##Colorbar shows the values of the weights
#Select the same class explained on the figures above.
ind =  explanation.top_labels[0]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

"""### 4.1.2 Testando o Lime no modelo Mobile Net para a Café - Cercospirose"""

#Predizendo e plotando a imagem com as informações da categoria
x409 = cv2.resize(X[409], IMAGE_SHAPE)
x409 = x409/255

y[409]

plt.imshow(x409)
predicted = model_netv2.predict(np.array([x409]))
for x in np.argmax(predicted,axis=1):
    print(x)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels
# explanation = explainer.explain_instance(x409, model_netv2.predict, top_labels=5, hide_color=0, num_samples=1000)
# explanation

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
##pros in green
##cons in red
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Explaination Heatmap plot with weights
##Colorbar shows the values of the weights
#Select the same class explained on the figures above.
ind =  explanation.top_labels[0]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

"""### 4.1.3 Testando o Lime no modelo Mobile Net para a Café - Phoma"""

#Predizendo e plotando a imagem com as informações da categoria
x519 = cv2.resize(X[519], IMAGE_SHAPE)
x519 = x519/255

y[519]

plt.imshow(x519)
predicted = model_netv2.predict(np.array([x519]))
for x in np.argmax(predicted,axis=1):
    print(x)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels
# explanation = explainer.explain_instance(x519, model_netv2.predict, top_labels=5, hide_color=0, num_samples=1000)
# explanation

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
##pros in green
##cons in red
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False, min_weight = 0.1)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Explaination Heatmap plot with weights
##Colorbar shows the values of the weights
#Select the same class explained on the figures above.
ind =  explanation.top_labels[0]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

"""### 4.1.4 Testando o Lime no modelo Mobile Net para a Café - Mantegosa"""

#Predizendo e plotando a imagem com as informações da categoria
x620 = cv2.resize(X[620], IMAGE_SHAPE)
x620 = x620/255

y[620]

plt.imshow(x620)
predicted = model_netv2.predict(np.array([x620]))
for x in np.argmax(predicted,axis=1):
    print(x)

# Commented out IPython magic to ensure Python compatibility.
# %%time
# # Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels
# explanation = explainer.explain_instance(x620, model_netv2.predict, top_labels=5, hide_color=0, num_samples=1000)
# explanation

temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=True)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=20, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Visualizing 'pros and cons'
##pros in green
##cons in red
temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=20, hide_rest=False)
plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))

#Explaination Heatmap plot with weights
##Colorbar shows the values of the weights
#Select the same class explained on the figures above.
ind =  explanation.top_labels[0]

#Map each explanation weight to the corresponding superpixel
dict_heatmap = dict(explanation.local_exp[ind])
heatmap = np.vectorize(dict_heatmap.get)(explanation.segments)

#Plot. The visualization makes more sense if a symmetrical colorbar is used.
plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())
plt.colorbar()

"""##4.2 SHAP

## https://www.youtube.com/watch?v=Re4HCqaQIyY
##https://h1ros.github.io/posts/explain-image-classification-by-shap-deep-explainer/
"""

!pip install shap

import shap
import tensorflow as tf

from tensorflow.keras.applications import mobilenet_v2
from tensorflow.keras.applications import imagenet_utils

x1 = cv2.resize(X[1], IMAGE_SHAPE)
x1 = np.array(x1)
x1 = np.expand_dims(x1, axis=0)
x = mobilenet_v2.preprocess_input(X)

def f(X):
    tmp = X.copy()
    #preprocess_input(tmp)
    return model_netv2(tmp)

## define a masker that is used to mask out partitions of the input image.
#masker = shap.maskers.Image("inpaint_telea",X[0].shape)

##class_names = coffee_leaves_labels_dict[doenca]

#explainer_shap = shap.Explainer(f, masker)

#shap_values = explainer_shap(x, max_evals=1000, batch_size=5)
#shap.image_plot(shap_values)

def img_prep(infile, add_batch_dim=True):
  img = infile
  img_a = np.array(img)
  if add_batch_dim:
    img_a = np.expand_dims(img_a, axis=0)
  m = mobilenet_v2.preprocess_input(img_a)
  return m

shap_explainer = shap.GradientExplainer(
  model= model_netv2,
  data= mobilenet_v2.preprocess_input(X))

"""### 5.1 SHAP - Ferrugem"""

infile = X[38]
x = img_prep(infile)

shap_values, top_ind = shap_explainer.shap_values(x, ranked_outputs=2)

shap.image_plot(shap_values, x)

"""### 5.2 SHAP - Cercospirose"""

infile = X[409]
x = img_prep(infile)

shap_values, top_ind = shap_explainer.shap_values(x, ranked_outputs=2)

shap.image_plot(shap_values, x)

"""### 5.3 SHAP - Phoma"""

infile = X[519]
x = img_prep(infile)

shap_values, top_ind = shap_explainer.shap_values(x, ranked_outputs=2)

shap.image_plot(shap_values, x)

"""### 5.4 SHAP - Mantegosa"""

infile = X[620]
x = img_prep(infile)

shap_values, top_ind = shap_explainer.shap_values(x, ranked_outputs=2)

shap.image_plot(shap_values, x)

"""#5 Testando Modelo VGG16

##https://towardsdatascience.com/transfer-learning-with-vgg16-and-keras-50ea161580b4
"""

from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
from keras.applications.vgg16 import preprocess_input
from keras.preprocessing import image
import tensorflow_datasets as tfds
from tensorflow.keras.utils import to_categorical

IMAGE_SIZE = [224,224]
## Loading VGG16 model
vgg = VGG16(input_shape=IMAGE_SIZE+[3], weights="imagenet", include_top=False)

for layer in vgg.layers:
  layer.trainable = False ## Not trainable weights

vgg.summary()

train_ds = X_train
train_labels =  y_train
test_ds = X_test
test_labels = y_test

# Resizing images
train_ds = tf.image.resize(train_ds, (224,224))
test_ds = tf.image.resize(test_ds, (224,224))

## Transforming labels to correct format
train_labels = to_categorical(train_labels, num_classes=4)
test_labels = to_categorical(test_labels, num_classes=4)

## Loading VGG16 model
base_model = VGG16(input_shape=IMAGE_SIZE+[3], weights="imagenet", include_top=False)
base_model.trainable = False ## Not trainable weights

## Preprocessing input
train_ds = preprocess_input(train_ds)
test_ds = preprocess_input(test_ds)

#Adding the last layers for our specific problem
from tensorflow.keras import layers, models

flatten_layer = layers.Flatten()
dense_layer_1 = layers.Dense(50, activation='relu')
dense_layer_2 = layers.Dense(20, activation='relu')
prediction_layer = layers.Dense(4, activation='softmax')


model_vgg16 = models.Sequential([
    base_model,
    flatten_layer,
    dense_layer_1,
    dense_layer_2,
    prediction_layer
])

from tensorflow.keras.callbacks import EarlyStopping

model_vgg16.compile(
    optimizer='adam',
    loss='categorical_crossentropy',
    metrics=['accuracy', 'mse']
)


es = EarlyStopping(monitor= 'val_loss', mode='min', patience=5,  restore_best_weights=True)

model_vgg16.fit(train_ds, train_labels, epochs=5, callbacks=[es])

#Avaliando a performance do modelo
model_vgg16.evaluate(test_ds,test_labels)

y_pred = []
for x in test_ds:
  pred = model_vgg16.predict(np.array([x]))
  pred = np.argmax(pred)
  y_pred.append(pred)

#y_test = y_test.tolist()
y_true = y_test
y_pred = y_pred

from sklearn.metrics import f1_score
f1 = f1_score(y_true,y_pred,average='weighted')
print(f1)

Categories = ['ferrugem','cercosporiose','phoma','manteigosa']
from sklearn.metrics import confusion_matrix
import seaborn as sns
mat = confusion_matrix(y_test, y_pred)
sns.heatmap(mat.T, square=True, annot=True, fmt='d',
            cbar=False, cmap='Blues',
            xticklabels=Categories,
            yticklabels=Categories)
plt.xlabel('true label')
plt.ylabel('predicted label');

Categories = ['ferrugem','cercosporiose','phoma','manteigosa']

fig, ax = plt.subplots(4, 6)
for i, axi in enumerate(ax.flat):
    axi.imshow(X_test[i].reshape(224,224,3), cmap='bone')
    axi.set(xticks=[], yticks=[])
    axi.set_ylabel(Categories[y_pred[i]].split()[-1],
                   color='black' if y_pred[i] == y_test[i] else 'red')
fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);

#Predizendo e plotando a imagem com as informações da categoria
x38 = cv2.resize(X[38], IMAGE_SHAPE)

plt.imshow(x38)
predicted = model_vgg16.predict(np.array([x38]))
for x in np.argmax(predicted,axis=1):
    print(x)

"""#6 Testando Modelo SVM

##https://medium.com/analytics-vidhya/image-classification-using-machine-learning-support-vector-machine-svm-dc7a0ec92e01

##https://colab.research.google.com/github/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.07-Support-Vector-Machines.ipynb#scrollTo=dIotAC_Yx1VI
"""

from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline

IMAGE_SHAPE = (224, 224)

#Ajuste no shape/size do banco de dados
X, y = [], []

for doenca, imagePath in coffee_leaves_images_dict.items():
    for imagePath in imagePath:
        ##Ajustando o tamanho das imagens
        resized_img = cv2.resize(imagePath,IMAGE_SHAPE)
        X.append(resized_img.flatten())
        y.append(coffee_leaves_labels_dict[doenca])

#Normalizando as imagens
X = np.array(X)
y = np.array(y)

#Train Test Split
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,
                                               random_state=0,
                                               stratify=y)

from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

pca = PCA(n_components=150, whiten=True,
          svd_solver='randomized', random_state=42)
svc = SVC(kernel='rbf', class_weight='balanced')
model = make_pipeline(pca, svc)
#model = make_pipeline(svc)

pca_aval = pca.fit(X_train)
plt.plot(np.cumsum(pca_aval.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');

# Commented out IPython magic to ensure Python compatibility.
param_grid = {'svc__C': [5, 10, 50,100],
              'svc__gamma': [0.0001, 0.0005, 0.001, 0.005]}
grid = GridSearchCV(model, param_grid)

# %time grid.fit(X_train, y_train)
print(grid.best_params_)

model = grid.best_estimator_
yfit = model.predict(X_test)

Categories = ['ferrugem','cercospirose','phoma','mantegosa']
from sklearn.metrics import classification_report
print(classification_report(y_test, yfit,
                            target_names=Categories))

fig, ax = plt.subplots(4, 6)
for i, axi in enumerate(ax.flat):
    axi.imshow(X_test[i].reshape(224,224,3), cmap='bone')
    axi.set(xticks=[], yticks=[])
    axi.set_ylabel(Categories[yfit[i]].split()[-1],
                   color='black' if yfit[i] == y_test[i] else 'red')
fig.suptitle('Predicted Names; Incorrect Labels in Red', size=14);

from sklearn.metrics import confusion_matrix
import seaborn as sns
mat = confusion_matrix(y_test, yfit)
sns.heatmap(mat.T, square=True, annot=True, fmt='d',
            cbar=False, cmap='Blues',
            xticklabels=Categories,
            yticklabels=Categories)
plt.xlabel('true label')
plt.ylabel('predicted label');

